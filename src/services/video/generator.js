const ffmpeg = require('fluent-ffmpeg');
const { supabase, openai } = require('../../config');
const { VIDEO_CONFIG, COLOR_GRADING, KEN_BURNS, PATRONES_PAN } = require('../../config');
const fs = require('fs');
const fsPromises = require('fs').promises;
const path = require('path');

/**
 * Detectar si un archivo es video
 * @param {string} rutaArchivo - Ruta del archivo
 * @returns {boolean}
 */
function esVideo(rutaArchivo) {
  const extension = path.extname(rutaArchivo).toLowerCase();
  return ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.m4v'].includes(extension);
}

/**
 * Detectar si un archivo es imagen
 * @param {string} rutaArchivo - Ruta del archivo
 * @returns {boolean}
 */
function esImagen(rutaArchivo) {
  const extension = path.extname(rutaArchivo).toLowerCase();
  return ['.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp'].includes(extension);
}

/**
 * Obtener duraci√≥n de un video
 * @param {string} rutaVideo - Ruta del video
 * @returns {Promise<number>} - Duraci√≥n en segundos
 */
async function obtenerDuracionVideo(rutaVideo) {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(rutaVideo, (err, metadata) => {
      if (err) {
        reject(err);
      } else {
        resolve(metadata.format.duration || 0);
      }
    });
  });
}

/**
 * Generar video con FFmpeg usando efecto Ken Burns, panning y color grading
 * Soporta mezcla de videos e im√°genes
 * @param {Array} rutasMedias - Array de rutas de im√°genes/videos ordenadas
 * @param {string} rutaAudio - Ruta del archivo de audio
 * @param {number} duracionPorSegmento - Duraci√≥n base en segundos para cada segmento
 * @param {string} rutaSalida - Ruta del video de salida
 * @param {string} rutaASS - Ruta del archivo de subt√≠tulos ASS (opcional)
 * @param {Object} opciones - Opciones adicionales (formato16x9, musicaVolumen, etc)
 * @returns {Promise<string>} - Ruta del video generado
 */
async function generarVideo(rutasMedias, rutaAudio, duracionPorSegmento, rutaSalida, rutaASS = null, opciones = {}) {
  return new Promise(async (resolve, reject) => {
    try {
      console.log('\nüîç === INFORMACI√ìN DE DEPURACI√ìN ===');
      console.log('üé¨ Iniciando generaci√≥n de video con soporte de videos e im√°genes...');
      console.log(`   - Total de medias: ${rutasMedias.length}`);
      console.log(`   - Duraci√≥n base por segmento: ${duracionPorSegmento.toFixed(2)}s`);
      
      // Configuraci√≥n de video - Soportar formato 16:9 para videos largos
      const fps = VIDEO_CONFIG.fps || 30;
      const formato16x9 = opciones.formato16x9 || false;
      const width = formato16x9 ? 1920 : (VIDEO_CONFIG.width || 1080);
      const height = formato16x9 ? 1080 : (VIDEO_CONFIG.height || 1920);
      
      console.log(`   - Formato: ${formato16x9 ? '16:9 (1920x1080)' : '9:16 (1080x1920)'}`);
      
      // Obtener duraci√≥n del audio primero
      console.log('üéµ Obteniendo duraci√≥n del audio...');
      const duracionAudio = await obtenerDuracionVideo(rutaAudio);
      console.log(`   - Duraci√≥n del audio: ${duracionAudio.toFixed(2)}s`);
      
      // Analizar cada media y determinar su duraci√≥n real
      const mediasInfo = [];
      for (let i = 0; i < rutasMedias.length; i++) {
        const rutaMedia = rutasMedias[i];
        const info = {
          ruta: rutaMedia,
          esVideo: esVideo(rutaMedia),
          esImagen: esImagen(rutaMedia),
          duracionSegmento: duracionPorSegmento,
          necesitaRecorte: false
        };

        if (info.esVideo) {
          try {
            const duracionOriginal = await obtenerDuracionVideo(rutaMedia);
            // Estrategia h√≠brida: usar duraci√≥n original si <= duracionPorSegmento, sino recortar
            info.duracionSegmento = Math.min(duracionOriginal, duracionPorSegmento);
            info.necesitaRecorte = duracionOriginal > duracionPorSegmento;
            console.log(`   [${i}] üé• VIDEO: ${path.basename(rutaMedia)}`);
            console.log(`       Duraci√≥n original: ${duracionOriginal.toFixed(2)}s`);
            console.log(`       Duraci√≥n a usar: ${info.duracionSegmento.toFixed(2)}s ${info.necesitaRecorte ? '(recortado)' : '(completo)'}`);
          } catch (error) {
            console.error(`       ‚ö†Ô∏è Error al obtener duraci√≥n:`, error.message);
            // Si falla, usar duraci√≥n base
            info.duracionSegmento = duracionPorSegmento;
          }
        } else if (info.esImagen) {
          console.log(`   [${i}] üñºÔ∏è  IMAGEN: ${path.basename(rutaMedia)}`);
          console.log(`       Duraci√≥n inicial: ${duracionPorSegmento}s`);
        }

        mediasInfo.push(info);
      }
      
      // Calcular duraci√≥n total de videos y medias
      const duracionTotalInicial = mediasInfo.reduce((sum, m) => sum + m.duracionSegmento, 0);
      const diferencia = duracionAudio - duracionTotalInicial;
      
      console.log(`   - Duraci√≥n total inicial de medias: ${duracionTotalInicial.toFixed(2)}s`);
      console.log(`   - Diferencia con audio: ${diferencia.toFixed(2)}s`);
      
      // Si hay diferencia, ajustar solo las im√°genes proporcionalmente
      if (Math.abs(diferencia) > 0.1) {
        const imagenes = mediasInfo.filter(m => m.esImagen);
        if (imagenes.length > 0) {
          const ajustePorImagen = diferencia / imagenes.length;
          console.log(`   - Ajustando ${imagenes.length} im√°genes en ${ajustePorImagen.toFixed(2)}s cada una`);
          
          imagenes.forEach(img => {
            img.duracionSegmento += ajustePorImagen;
            // Asegurar que no sea negativa
            if (img.duracionSegmento < 0.5) img.duracionSegmento = 0.5;
          });
        }
      }
      
      const duracionTotalFinal = mediasInfo.reduce((sum, m) => sum + m.duracionSegmento, 0);
      console.log(`   - Duraci√≥n total ajustada: ${duracionTotalFinal.toFixed(2)}s`);
      console.log(`   - Coincide con audio: ${Math.abs(duracionTotalFinal - duracionAudio) < 0.1 ? '‚úÖ S√ç' : '‚ö†Ô∏è  NO'}`);
      
      // Verificar archivos de media
      console.log('\nüìÅ Verificando archivos de media:');
      for (let i = 0; i < mediasInfo.length; i++) {
        const info = mediasInfo[i];
        const existe = fs.existsSync(info.ruta);
        if (!existe) {
          console.error(`   [${i}] ‚ùå NO EXISTE: ${info.ruta}`);
          throw new Error(`Archivo no encontrado: ${info.ruta}`);
        }
        
        const stats = fs.statSync(info.ruta);
        const tipo = info.esVideo ? 'üé• VIDEO' : 'üñºÔ∏è  IMAGEN';
        console.log(`   [${i}] ‚úÖ ${tipo}: ${path.basename(info.ruta)} (${(stats.size / 1024).toFixed(2)} KB)`);
        
        // Obtener metadata usando ffprobe
        try {
          const probe = await new Promise((res, rej) => {
            ffmpeg.ffprobe(info.ruta, (err, metadata) => {
              if (err) rej(err);
              else res(metadata);
            });
          });
          const videoStream = probe.streams.find(s => s.codec_type === 'video');
          if (videoStream) {
            console.log(`       Resoluci√≥n: ${videoStream.width}x${videoStream.height}`);
            console.log(`       Codec: ${videoStream.codec_name}`);
          }
        } catch (probeErr) {
          console.warn(`       ‚ö†Ô∏è  No se pudo obtener metadata: ${probeErr.message}`);
        }
      }
      
      // Verificar audio
      console.log('\nüéµ Verificando audio:');
      const audioExiste = fs.existsSync(rutaAudio);
      if (audioExiste) {
        const audioStats = fs.statSync(rutaAudio);
        console.log(`   ‚úÖ ${path.basename(rutaAudio)} (${(audioStats.size / 1024).toFixed(2)} KB)`);
        
        try {
          const audioProbe = await new Promise((res, rej) => {
            ffmpeg.ffprobe(rutaAudio, (err, metadata) => {
              if (err) rej(err);
              else res(metadata);
            });
          });
          const audioStream = audioProbe.streams.find(s => s.codec_type === 'audio');
          if (audioStream) {
            console.log(`   Duraci√≥n: ${audioProbe.format.duration}s`);
            console.log(`   Codec: ${audioStream.codec_name}`);
            console.log(`   Sample rate: ${audioStream.sample_rate} Hz`);
            console.log(`   Channels: ${audioStream.channels}`);
            console.log(`   Bitrate: ${audioProbe.format.bit_rate ? (audioProbe.format.bit_rate / 1000).toFixed(0) : 'N/A'} kbps`);
          }
        } catch (probeErr) {
          console.warn(`   ‚ö†Ô∏è  No se pudo obtener metadata de audio: ${probeErr.message}`);
        }
      } else {
        console.error(`   ‚ùå NO EXISTE: ${rutaAudio}`);
        throw new Error(`Audio no encontrado: ${rutaAudio}`);
      }
      
      if (rutaASS) {
        console.log('\nüìù Archivo de subt√≠tulos:');
        const assExiste = fs.existsSync(rutaASS);
        if (assExiste) {
          const assStats = fs.statSync(rutaASS);
          console.log(`   ‚úÖ ${path.basename(rutaASS)} (${(assStats.size / 1024).toFixed(2)} KB)`);
        } else {
          console.warn(`   ‚ö†Ô∏è  NO EXISTE: ${rutaASS}`);
        }
      }
      
      console.log('\nüé¨ === INICIANDO GENERACI√ìN ===\n');

      // Paso 1: Generar video base sin subt√≠tulos
      const rutaVideoTemp = rutaASS ? rutaSalida.replace('.mp4', '_temp.mp4') : rutaSalida;
      
      // Crear filtros complejos para efecto Ken Burns
      const filtros = [];

      // Generar filtros para cada media (Ken Burns para im√°genes, scale+crop para videos)
      mediasInfo.forEach((info, index) => {
        const inputLabel = `[${index}:v]`;
        const outputLabel = `[v${index}]`;
        
        if (info.esImagen) {
          const duracionFrames = Math.floor(info.duracionSegmento * fps);
          
          if (formato16x9) {
            // VIDEOS LARGOS (16:9): Paneo horizontal puro sin zoom
            // Alternamos direcci√≥n: izquierda‚Üíderecha, derecha‚Üíizquierda
            const direccion = index % 2 === 0 ? 'L->R' : 'R->L';
            console.log(`   üñºÔ∏è  Imagen ${index + 1}: Paneo horizontal ${direccion} (${info.duracionSegmento.toFixed(2)}s)`);
            
            // Usar tblend + overlay para simular movimiento, o mejor: loop + crop animado
            // Primero necesitamos convertir imagen est√°tica en video con loop
            
            const anchoEscalado = width * 2; // 3840 para paneo
            const distanciaMovimiento = Math.round(width * 0.33); // 33% del ancho = 640px (paneo m√°s lento y sutil)
            
            // Expresi√≥n de crop con 'n' (frame number) para movimiento
            let cropX;
            if (index % 2 === 0) {
              // Izquierda ‚Üí Derecha: x = n * (640 / total_frames)
              cropX = `'min(n*${distanciaMovimiento / duracionFrames},${distanciaMovimiento})'`;
            } else {
              // Derecha ‚Üí Izquierda: x = 640 - n * (640 / total_frames)
              cropX = `'max(${distanciaMovimiento}-n*${distanciaMovimiento / duracionFrames},0)'`;
            }
            
            // Filtro completo:
            // 1. scale + crop: preparar imagen a 3840x1080
            // 2. loop: convertir imagen est√°tica en video de N frames
            // 3. crop: recorte animado usando 'n' para coordenada X
            // 4. fps, setsar, setpts: normalizaci√≥n
            const filtro = `${inputLabel}scale=${anchoEscalado}:${height}:force_original_aspect_ratio=increase,crop=${anchoEscalado}:${height},loop=loop=${duracionFrames}:size=1:start=0,crop=${width}:${height}:${cropX}:0,fps=${fps},setsar=1,setpts=PTS-STARTPTS${outputLabel}`;
            
            filtros.push(filtro);
          } else {
            // VIDEOS CORTOS (9:16): Aplicar Ken Burns con zoompan
            const mitadDuracion = duracionFrames / 2;
            
            // Seleccionar patr√≥n de paneo seg√∫n el √≠ndice (se repite cada 4 medias)
            const patron = PATRONES_PAN[index % PATRONES_PAN.length];
            console.log(`   üñºÔ∏è  Imagen ${index + 1}: Ken Burns + Paneo ${patron.nombre} (${info.duracionSegmento.toFixed(2)}s)`);
            
            // Calcular movimiento de paneo con easing suave (ease-in-out)
            // Usa pow(3) para distribuir mejor el movimiento durante toda la duraci√≥n
            let paneoX, paneoY;
            
            if (patron.factorX !== undefined) {
              // Paneo horizontal con easing muy pronunciado (pow 8)
              const inicio = patron.factorX;
              const rango = Math.abs(patron.factorX) * 2;
              
              paneoX = `iw/2-(iw/zoom/2) + iw*${inicio}*(1-1/zoom) + iw*${rango}*${patron.direccionX}*(1-1/zoom)*if(lte(on,${mitadDuracion}),(1-pow(1-on/${mitadDuracion},8)),pow((on-${mitadDuracion})/${mitadDuracion},8))`;
              paneoY = `ih/2-(ih/zoom/2)`;
            } else {
              // Paneo vertical con easing muy pronunciado (pow 8)
              const inicio = patron.factorY;
              const rango = Math.abs(patron.factorY) * 2;
              
              paneoX = `iw/2-(iw/zoom/2)`;
              paneoY = `ih/2-(ih/zoom/2) + ih*${inicio}*(1-1/zoom) + ih*${rango}*${patron.direccionY}*(1-1/zoom)*if(lte(on,${mitadDuracion}),(1-pow(1-on/${mitadDuracion},8)),pow((on-${mitadDuracion})/${mitadDuracion},8))`;
            }
            
            // F√≥rmula de zoom con easing ease-in-out (pow 8)
            // Zoom OUT (1.7x ‚Üí 1.0x) primera mitad, Zoom IN (1.0x ‚Üí 1.7x) segunda mitad
            // El pow(8) distribuye: ~90% movimiento en primeros/√∫ltimos 15%, muy est√°tico en el medio
            const filtro = `${inputLabel}scale=${width}:${height}:force_original_aspect_ratio=increase,crop=${width}:${height},setsar=1,zoompan=z='if(lte(on,${mitadDuracion}),1.7-0.7*(1-pow(1-on/${mitadDuracion},8)),1.0+0.7*pow((on-${mitadDuracion})/${mitadDuracion},8))':d=${duracionFrames}:x='${paneoX}':y='${paneoY}':s=${width}x${height},fps=${fps},setpts=PTS-STARTPTS${outputLabel}`;
            
            filtros.push(filtro);
          }
        } else if (info.esVideo) {
          // VIDEOS: Solo scale, crop y normalizaci√≥n (sin zoompan para preservar movimiento)
          console.log(`   üé• Video ${index + 1}: Scale + Crop (preservando movimiento) (${info.duracionSegmento.toFixed(2)}s)`);
          
          // Para videos: scale, crop, normalizar fps y setsar
          const filtro = `${inputLabel}scale=${width}:${height}:force_original_aspect_ratio=increase,crop=${width}:${height},setsar=1,fps=${fps},setpts=PTS-STARTPTS${outputLabel}`;
          
          filtros.push(filtro);
        }
      });

      // Concatenar todos los clips
      const concatInputs = mediasInfo.map((_, index) => `[v${index}]`).join('');
      filtros.push(`${concatInputs}concat=n=${mediasInfo.length}:v=1:a=0[v_concat]`);
      
      // Aplicar Color Grading
      console.log('üé® Aplicando color grading profesional...');
      filtros.push(`[v_concat]eq=saturation=${COLOR_GRADING.saturation}:brightness=${COLOR_GRADING.brightness}:contrast=${COLOR_GRADING.contrast}[outv]`);

      const filterComplex = filtros.join(';');

      // Crear comando FFmpeg para video base
      let comando = ffmpeg();

      // Agregar todas las medias como inputs
      // Para im√°genes: el zoompan maneja la duraci√≥n con el par√°metro 'd'
      // Para videos: aplicamos -t si necesitan recorte
      mediasInfo.forEach(info => {
        if (info.esImagen) {
          // Im√°genes: agregar sin opciones, zoompan controla la duraci√≥n
          comando = comando.input(info.ruta);
        } else if (info.esVideo) {
          // Videos: si necesita recorte, aplicar -t para duraci√≥n
          if (info.necesitaRecorte) {
            comando = comando.input(info.ruta).inputOptions(['-t', info.duracionSegmento.toString()]);
          } else {
            comando = comando.input(info.ruta);
          }
        }
      });

      // Agregar audio
      comando = comando.input(rutaAudio);

      // Aplicar configuraci√≥n
      await new Promise((resolveBase, rejectBase) => {
        comando
          .complexFilter(filterComplex)
          .outputOptions([
            '-map [outv]',
            `-map ${mediasInfo.length}:a`,
            '-c:v ' + VIDEO_CONFIG.codec,
            '-preset ' + VIDEO_CONFIG.preset,
            '-crf ' + VIDEO_CONFIG.crf,
            '-pix_fmt ' + VIDEO_CONFIG.pixelFormat,
            '-c:a aac',
            '-b:a 192k',
            `-t ${duracionAudio.toFixed(3)}`
          ])
          .output(rutaVideoTemp)
          .on('start', (commandLine) => {
            console.log('üé• Generando video base con efecto Ken Burns...');
            console.log('\nüîß Comando FFmpeg completo:');
            console.log(commandLine);
            console.log('');
          })
          .on('progress', (progress) => {
            if (progress.percent) {
              process.stdout.write(`\r‚è≥ Progreso video base: ${progress.percent.toFixed(1)}%`);
            }
          })
          .on('end', () => {
            console.log('\n‚úÖ Video base generado');
            resolveBase();
          })
          .on('error', (error, stdout, stderr) => {
            console.error('\n‚ùå Error generando video base:', error.message);
            console.error('\nüìã STDERR de FFmpeg:');
            console.error(stderr || 'No stderr disponible');
            console.error('\nüìã STDOUT de FFmpeg:');
            console.error(stdout || 'No stdout disponible');
            rejectBase(error);
          })
          .run();
      });

      // Paso 2: Si hay subt√≠tulos, agregarlos al video
      if (rutaASS) {
        console.log('üìù Agregando subt√≠tulos al video...');
        const rutaASSEscapada = rutaASS.replace(/\\/g, '/').replace(/:/g, '\\:');
        
        await new Promise((resolveSubs, rejectSubs) => {
          ffmpeg(rutaVideoTemp)
            .outputOptions([
              `-vf ass='${rutaASSEscapada}'`,
              '-c:a copy'
            ])
            .output(rutaSalida)
            .on('start', () => {
              console.log('üé® Aplicando subt√≠tulos...');
            })
            .on('progress', (progress) => {
              if (progress.percent) {
                process.stdout.write(`\r‚è≥ Progreso subt√≠tulos: ${progress.percent.toFixed(1)}%`);
              }
            })
            .on('end', () => {
              console.log('\n‚úÖ Subt√≠tulos agregados');
              // Eliminar video temporal
              try {
                fs.unlinkSync(rutaVideoTemp);
              } catch (e) {
                console.warn('‚ö†Ô∏è  No se pudo eliminar video temporal:', e.message);
              }
              resolveSubs();
            })
            .on('error', (error) => {
              console.error('\n‚ùå Error agregando subt√≠tulos:', error.message);
              rejectSubs(error);
            })
            .run();
        });
      }

      console.log('‚úÖ Video completo generado exitosamente');
      resolve(rutaSalida);
      
    } catch (error) {
      console.error('‚ùå Error en generarVideo:', error.message);
      reject(error);
    }
  });
}

module.exports = {
  generarVideo
};
